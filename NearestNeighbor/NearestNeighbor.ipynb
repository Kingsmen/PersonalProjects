{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg as la\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exhaustive_search(X, z):\n",
    "    \"\"\"Solve the nearest neighbor search problem with an exhaustive search.\n",
    "\n",
    "    Parameters:\n",
    "        X ((m,k) ndarray): a training set of m k-dimensional points.\n",
    "        z ((k, ) ndarray): a k-dimensional target point.\n",
    "\n",
    "    Returns:\n",
    "        ((k,) ndarray) the element (row) of X that is nearest to z.\n",
    "        (float) The Euclidean distance from the nearest neighbor to z.\n",
    "    \"\"\"\n",
    "    dist = la.norm(X - z, axis = 1)\n",
    "    return X[np.argmin(dist)], min(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_exhaustive():\n",
    "\tA = np.array([[1, 2, 3]])\n",
    "\tz = np.array([6, 5, 4])\n",
    "\tassert np.allclose(exhaustive_search(A,z)[0], np.array([1,2,3]))\n",
    "\tassert exhaustive_search(A,z)[1] == 5.9160797830996161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_exhaustive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDTnode:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        x ((1,k) ndarray): vector of data\n",
    "\n",
    "    Attributes:\n",
    "        value(np.ndarray): vector of data\n",
    "        left(KDTnode): left child node\n",
    "        right(KDTnode): right child node\n",
    "        pivot(int): integer mod k \n",
    "    \"\"\"\n",
    "    def __init__(self, x):\n",
    "        \"\"\"Initialize value, left, right and pivot. \n",
    "        Do error checking on x\n",
    "        \"\"\"\n",
    "        if type(x) == np.ndarray:\n",
    "            self.value = x\n",
    "            self.left = None\n",
    "            self.right = None\n",
    "            self.pivot = None\n",
    "        else:\n",
    "            raise ValueError(\"x must be ndarray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDT:\n",
    "    \"\"\"A k-dimensional binary tree for solving the nearest neighbor problem.\n",
    "\n",
    "    Attributes:\n",
    "        root (KDTNode): the root node of the tree. Like all other nodes in\n",
    "            the tree, the root has a NumPy array of shape (k,) as its value.\n",
    "        k (int): the dimension of the data in the tree.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the root and k attributes.\"\"\"\n",
    "        self.root = None\n",
    "        self.k = None\n",
    "        self.z = None\n",
    "\n",
    "    def find(self, data):\n",
    "        \"\"\"Return the node containing the data. If there is no such node in\n",
    "        the tree, or if the tree is empty, raise a ValueError.\n",
    "        \"\"\"\n",
    "        def _step(current):\n",
    "            \"\"\"Recursively step through the tree until finding the node\n",
    "            containing the data. If there is no such node, raise a ValueError.\n",
    "            \"\"\"\n",
    "            if current is None:                     # Base case 1: dead end.\n",
    "                raise ValueError(str(data) + \" is not in the tree\")\n",
    "            elif np.allclose(data, current.value):\n",
    "                return current                      # Base case 2: data found!\n",
    "            elif data[current.pivot] < current.value[current.pivot]:\n",
    "                return _step(current.left)          # Recursively search left.\n",
    "            else:\n",
    "                return _step(current.right)         # Recursively search right.\n",
    "\n",
    "        # Start the recursive search at the root of the tree.\n",
    "        return _step(self.root)\n",
    "\n",
    "    # Problem 3\n",
    "    def insert(self, data):\n",
    "        \"\"\"Insert a new node containing the specified data.\n",
    "\n",
    "        Parameters:\n",
    "            data ((k,) ndarray): a k-dimensional point to insert into the tree.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: if data does not have the same dimensions as other\n",
    "                values in the tree.\n",
    "        \"\"\"\n",
    "        found = False #used to determin if a duplicate is found\n",
    "\n",
    "        if type(data) != np.ndarray:\n",
    "            raise ValueError(\"Not an array\")\n",
    "        if self.k != None and self.k != len(data): #if not empty check data length\n",
    "            raise ValueError(\"Data is not in R^k\") \n",
    "\n",
    "        #Tree is empty\n",
    "        if self.root == None:\n",
    "            self.root = KDTnode(data)\n",
    "            self.k = len(data)\n",
    "            self.root.pivot = 0\n",
    "\n",
    "        #Tree is nonempty\n",
    "        elif self.root != None:\n",
    "            #Recursive parent finder/linker\n",
    "            def _parent(current):\n",
    "                \"\"\"Recursively step through graph until a parent with\n",
    "                null children is found.\n",
    "                \"\"\"\n",
    "\n",
    "                #recurse while children are not null\n",
    "                if data[current.pivot] < current.value[current.pivot] and current.left != None:\n",
    "                    return _parent(current.left)\n",
    "                elif data[current.pivot] >= current.value[current.pivot] and current.right != None:\n",
    "                    return _parent(current.right)\n",
    "\n",
    "                #found parent with null children\n",
    "                else:\n",
    "                    #Determin which child to insert into\n",
    "                    if data[current.pivot] < current.value[current.pivot]:\n",
    "                        current.left = KDTnode(data)\n",
    "                        current.left.pivot = (current.pivot + 1) % self.k\n",
    "                    elif data[current.pivot] >= current.value[current.pivot]:\n",
    "                        current.right = KDTnode(data)\n",
    "                        current.right.pivot = (current.pivot + 1) % self.k\n",
    "\n",
    "            #duplicate checking\n",
    "            try:\n",
    "                temp = self.find(data)\n",
    "                if temp != None:\n",
    "                    found = True\n",
    "\n",
    "            #if no duplicate is found\n",
    "            except ValueError as error:\n",
    "                _parent(self.root)\n",
    "            if found:\n",
    "                raise ValueError(\"No Duplicates\")\n",
    "\n",
    "    def _KDsearch(self, current, nearest, d):\n",
    "        \"\"\"Recursive function used in query\n",
    "        \"\"\"\n",
    "        if current is None:\n",
    "            return nearest, d\n",
    "        x = current.value\n",
    "        i = current.pivot\n",
    "\n",
    "        if la.norm(x - self.z) < d: \n",
    "            nearest = current\n",
    "            d = la.norm(x - self.z)\n",
    "\n",
    "        if self.z[i] < x[i]:\n",
    "            nearest, d = self._KDsearch(current.left, nearest, d)\n",
    "            if self.z[i] + d >= x[i]:\n",
    "                nearest, d = self._KDsearch(current.right, nearest,d)\n",
    "\n",
    "        else:\n",
    "            nearest,d = self._KDsearch(current.right, nearest, d)\n",
    "            if self.z[i] - d <= x[i]:\n",
    "                nearest,d = self._KDsearch(current.left,nearest,d)\n",
    "        return nearest, d\n",
    "\n",
    "    # Problem 4\n",
    "    def query(self, z):\n",
    "        \"\"\"Find the value in the tree that is nearest to z.\n",
    "\n",
    "        Parameters:\n",
    "            z ((k,) ndarray): a k-dimensional target point.\n",
    "\n",
    "        Returns:\n",
    "            ((k,) ndarray) the value in the tree that is nearest to z.\n",
    "            (float) The Euclidean distance from the nearest neighbor to z.\n",
    "        \"\"\"\n",
    "        self.z = z\n",
    "        a, b = self._KDsearch(self.root, self.root, la.norm(self.root.value - z))\n",
    "        return a.value, b\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"String representation: a hierarchical list of nodes and their axes.\n",
    "\n",
    "        Example:                           'KDT(k=2)\n",
    "                    [5,5]                   [5 5]   pivot = 0\n",
    "                    /                      [3 2]   pivot = 1\n",
    "                [3,2]   [8,4]               [8 4]   pivot = 1\n",
    "                                          [2 6]   pivot = 0\n",
    "                    [2,6]   [7,5]           [7 5]   pivot = 0'\n",
    "        \"\"\"\n",
    "        if self.root is None:\n",
    "            return \"Empty KDT\"\n",
    "        nodes, strs = [self.root], []\n",
    "        while nodes:\n",
    "            current = nodes.pop(0)\n",
    "            strs.append(\"{}\\tpivot = {}\".format(current.value, current.pivot))\n",
    "            for child in [current.left, current.right]:\n",
    "                if child:\n",
    "                    nodes.append(child)\n",
    "        return \"KDT(k={})\\n\".format(self.k) + \"\\n\".join(strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNeighborsClassifier:\n",
    "    \"\"\"\n",
    "    Attributes:\n",
    "        n(int): the number of voting neighbors\n",
    "        tree(KDTree): the representation of the matrix\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,n_neighbors):\n",
    "        \"\"\"Initialize the class with the integer representing the \n",
    "        number of neighbors\n",
    "        \"\"\"\n",
    "        self.n = n_neighbors\n",
    "        self.tree = None\n",
    "        self.label = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"A setter function that load\n",
    "        \"\"\"\n",
    "        self.tree = KDTree(X)\n",
    "        self.label = y\n",
    "\n",
    "    def predict(self, z):\n",
    "        \"\"\"Accepts an array z, runs KDTree.query on it\n",
    "        returns most common label\n",
    "        \"\"\"\n",
    "        dists, indices = self.tree.query(z, k = self.n)\n",
    "        return mode(self.label[indices])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestCase(n_neighbors, filename=\"mnist_subset.npz\"):\n",
    "    \"\"\"Extract the data from the given file. Load a KNeighborsClassifier with\n",
    "    the training data and the corresponding labels. Use the classifier to\n",
    "    predict labels for the test data. Return the classification accuracy, the\n",
    "    percentage of predictions that match the test labels.\n",
    "\n",
    "    Parameters:\n",
    "        n_neighbors (int): the number of neighbors to use for classification.\n",
    "        filename (str): the name of the data file. Should be an npz file with\n",
    "            keys 'X_train', 'y_train', 'X_test', and 'y_test'.\n",
    "\n",
    "    Returns:\n",
    "        (float): the classification accuracy.\n",
    "    \"\"\"\n",
    "    data = np.load(\"mnist_subset.npz\")\n",
    "    X_train = data[\"X_train\"].astype(np.float)\n",
    "    y_train = data[\"y_train\"]\n",
    "    X_test = data[\"X_test\"].astype(np.float)\n",
    "    y_test = data[\"y_test\"]\n",
    "    classifier = KNeighborsClassifier(n_neighbors)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    num_correct = 0\n",
    "    for i in range(len(X_test)):\n",
    "        if y_test[i] == classifier.predict(X_test[i]):\n",
    "            num_correct += 1\n",
    "    return num_correct/len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.906"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestCase(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
